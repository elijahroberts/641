{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import nltk\n",
        "from langdetect import detect\n",
        "from nltk.util import ngrams\n",
        "import spacy\n",
        "import yake\n",
        "from transformers import BertTokenizer, BertModel, AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import fasttext\n",
        "\n",
        "# Initialize the model and tokenizer\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "models = {\n",
        "    'en': AutoModelForSequenceClassification.from_pretrained('Worgu/Final_Project_finetuned_bert-base-multilingual-cased_english'),\n",
        "    'de': AutoModelForSequenceClassification.from_pretrained('Worgu/Final_Project_finetuned_bert-base-multilingual-cased_german'),\n",
        "    'fr': AutoModelForSequenceClassification.from_pretrained('Worgu/Final_Project_finetuned_bert-base-multilingual-cased_french'),\n",
        "    'es': AutoModelForSequenceClassification.from_pretrained('Worgu/Final_Project_finetuned_bert-base-multilingual-cased_spanish')}\n",
        "\n",
        "\n",
        "# Download NLTK stopwords and spacy model\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "spacy.cli.download(\"en_core_web_sm\")\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# YAKE keyword extraction\n",
        "yake_kw_extractor = yake.KeywordExtractor()\n",
        "\n",
        "\n",
        "def sentiment_analysis(review: str, lang):\n",
        "    inputs = tokenizer(review, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    model = models.get(lang, models['en'])  # Use English model as default\n",
        "    outputs = model(**inputs)\n",
        "    probabilities = F.softmax(outputs.logits, dim=1)\n",
        "    sentiment_idx = torch.argmax(probabilities).item()\n",
        "\n",
        "    sentiment_label = None\n",
        "    if sentiment_idx == 0:\n",
        "        sentiment_label = \" POSITIVE\"\n",
        "    elif sentiment_idx == 1:\n",
        "        sentiment_label = \"NEGATIVE\"\n",
        "    elif sentiment_idx == 2:\n",
        "        sentiment_label = \"NEUTRAL\"\n",
        "\n",
        "    return {\"label\": sentiment_label, \"score\": probabilities[0, sentiment_idx].item()}\n",
        "    \n",
        "\n",
        "def analyze_reviews(reviews: str):\n",
        "    reviews_list = reviews.split(\"\\n\")\n",
        "    results = []\n",
        "\n",
        "    for review in reviews_list:\n",
        "        detected_language = detect(review)\n",
        "        result = sentiment_analysis(review, detected_language)\n",
        "        result[\"language\"] = detected_language\n",
        "        result[\"review\"] = review\n",
        "        results.append(result)\n",
        "\n",
        "    return results\n",
        "\n",
        " \n",
        "def get_ngrams(text: str, n: int = 2):\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    n_grams = list(ngrams(tokens, n))\n",
        "    return n_grams\n",
        "\n",
        "def get_yake_keywords(text: str, n: int = 5):\n",
        "    return yake_kw_extractor.extract_keywords(text)[:n]\n",
        "\n",
        "def emoji(sentiment_score):\n",
        "    if sentiment_score >= 0.8:\n",
        "        return \"😄\"\n",
        "    elif sentiment_score >= 0.2 and sentiment_score < 0.8:\n",
        "        return \"😊\"\n",
        "    elif sentiment_score > -0.2 and sentiment_score < 0.2:\n",
        "        return \"😐\"\n",
        "    elif sentiment_score > -0.8 and sentiment_score <= -0.2:\n",
        "        return \"☹️\"\n",
        "    else:\n",
        "        return \"😠\"\n",
        "\n",
        "\n",
        "def main():\n",
        "    st.title(\"Multilingual Review Sentiment Analysis\")\n",
        "    st.write(\"\"\"\n",
        "    Enter your text in the text area below. You can input multiple texts separated by line breaks. The sentiment analysis results for each review will be displayed after analysis.\n",
        "    \"\"\")\n",
        "\n",
        "    reviews = st.text_area(\"Input your Amazon reviews here:\", height=200)\n",
        "\n",
        "    if st.button(\"Analyze text\"):\n",
        "        results = analyze_reviews(reviews)\n",
        "        for result in results:\n",
        "            sentiment_label_text = result['label']\n",
        "            sentiment_score = result['score']\n",
        "            sentiment_emoji = emoji(sentiment_score)\n",
        "\n",
        "            st.write(f\"Review: {result['review']} | Language: {result['language']} | Sentiment: {sentiment_label_text} {sentiment_emoji}\")\n",
        "\n",
        "        st.subheader(\"N-gram Analysis\")\n",
        "        n_value = st.slider(\"Select N value for N-grams:\", 2, 5, 2)\n",
        "        ngrams_list = get_ngrams(reviews, n=n_value)\n",
        "        st.write(f\"Top {n_value}-grams:\")\n",
        "        st.write(ngrams_list)\n",
        "\n",
        "        st.subheader(\"Keyword Extraction\")\n",
        "        num_keywords = st.slider(\"Select number of keywords to extract:\", 5, 20, 5)\n",
        "        yake_keywords = get_yake_keywords(reviews, n=num_keywords)\n",
        "        st.write(\"YAKE extracted keywords:\")\n",
        "        st.write(yake_keywords)\n",
        "\n",
        "        st.subheader(\"Summary Statistics\")\n",
        "        data = {\n",
        "            \"Sentiment Score\": [result[\"score\"] for result in results],\n",
        "            \"Language\": [result[\"language\"] for result in results]\n",
        "        }\n",
        "        df = pd.DataFrame(data)\n",
        "        st.write(df.describe())\n",
        "\n",
        "        st.subheader(\"Interactive Visualizations\")\n",
        "        fig = px.histogram(df, x=\"Sentiment Score\", nbins=20, title=\"Sentiment Score Distribution\")\n",
        "        st.plotly_chart(fig)\n",
        "\n",
        "        lang_count = df[\"Language\"].value_counts()\n",
        "        fig2 = px.pie(lang_count, values=lang_count.values, names=lang_count.index, title=\"Language Distribution\")\n",
        "        st.plotly_chart(fig2)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "DW35N9uneBVM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAHsY4P8-bSh",
        "outputId": "59ba3065-0860-40e0-d6d1-533be1ecc05e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import nltk\n",
        "from langdetect import detect\n",
        "from nltk.util import ngrams\n",
        "import spacy\n",
        "import yake\n",
        "from transformers import BertTokenizer, BertModel, AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Initialize the model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
        "model = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
        "\n",
        "\n",
        "# Download NLTK stopwords and spacy model\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "spacy.cli.download(\"en_core_web_sm\")\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# YAKE keyword extraction\n",
        "yake_kw_extractor = yake.KeywordExtractor()\n",
        "\n",
        "\n",
        "def sentiment_analysis(review: str):\n",
        "    inputs = tokenizer(review, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    outputs = model(**inputs)\n",
        "    probabilities = F.softmax(outputs.logits, dim=1)\n",
        "    sentiment_idx = torch.argmax(probabilities).item()\n",
        "    sentiment_score = probabilities[0, 2].item() - probabilities[0, 0].item()\n",
        "\n",
        "    sentiment_label = None\n",
        "    if sentiment_idx == 0:\n",
        "        sentiment_label = \" VERY NEGATIVE\"\n",
        "    elif sentiment_idx == 1:\n",
        "        sentiment_label = \"NEGATIVE\"\n",
        "    elif sentiment_idx == 2:\n",
        "        sentiment_label = \"NEUTRAL\"\n",
        "    elif sentiment_idx == 3:\n",
        "        sentiment_label = \"POSITIVE\"\n",
        "    elif sentiment_idx == 4:\n",
        "        sentiment_label = \"VERY POSITIVE\"\n",
        "\n",
        "    return {\"label\": sentiment_label, \"score\": sentiment_score}\n",
        "\n",
        "\n",
        "def analyze_reviews(reviews: str):\n",
        "    reviews_list = reviews.split(\"\\n\")\n",
        "    results = []\n",
        "\n",
        "    for review in reviews_list:\n",
        "        result = sentiment_analysis(review)\n",
        "        detected_language = fasttext_model.predict(review)[0][0].replace(\"__label__\", \"\")\n",
        "        result[\"language\"] = detected_language\n",
        "        result[\"review\"] = review\n",
        "        results.append(result)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def get_ngrams(text: str, n: int = 2):\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    n_grams = list(ngrams(tokens, n))\n",
        "    return n_grams\n",
        "\n",
        "def get_yake_keywords(text: str, n: int = 5):\n",
        "    return yake_kw_extractor.extract_keywords(text)[:n]\n",
        "\n",
        "def emoji(sentiment_score):\n",
        "    if sentiment_score >= 0.8:\n",
        "        return \"😄\"\n",
        "    elif sentiment_score >= 0.2 and sentiment_score < 0.8:\n",
        "        return \"😊\"\n",
        "    elif sentiment_score > -0.2 and sentiment_score < 0.2:\n",
        "        return \"😐\"\n",
        "    elif sentiment_score > -0.8 and sentiment_score <= -0.2:\n",
        "        return \"☹️\"\n",
        "    else:\n",
        "        return \"😠\"\n",
        "\n",
        "\n",
        "def main():\n",
        "    st.title(\"Multilingual Amazon Review Sentiment Analysis\")\n",
        "    st.write(\"\"\"\n",
        "    Enter your Amazon reviews in the text area below. You can input multiple texts separated by line breaks. The sentiment analysis results for each review will be displayed after analysis.\n",
        "    \"\"\")\n",
        "\n",
        "    reviews = st.text_area(\"Input your Amazon reviews here:\", height=200)\n",
        "\n",
        "    if st.button(\"Analyze Reviews\"):\n",
        "        results = analyze_reviews(reviews)\n",
        "        for result in results:\n",
        "            sentiment_label_text = result['label']\n",
        "            sentiment_score = result['score']\n",
        "            sentiment_emoji = emoji(sentiment_score)\n",
        "\n",
        "            st.write(f\"Review: {result['review']} | Language: {result['language']} | Sentiment: {sentiment_label_text} {sentiment_emoji}\")\n",
        "\n",
        "        st.subheader(\"N-gram Analysis\")\n",
        "        n_value = st.slider(\"Select N value for N-grams:\", 2, 5, 2)\n",
        "        ngrams_list = get_ngrams(reviews, n=n_value)\n",
        "        st.write(f\"Top {n_value}-grams:\")\n",
        "        st.write(ngrams_list)\n",
        "\n",
        "        st.subheader(\"Keyword Extraction\")\n",
        "        num_keywords = st.slider(\"Select number of keywords to extract:\", 5, 20, 5)\n",
        "        yake_keywords = get_yake_keywords(reviews, n=num_keywords)\n",
        "        st.write(\"YAKE extracted keywords:\")\n",
        "        st.write(yake_keywords)\n",
        "\n",
        "        st.subheader(\"Summary Statistics\")\n",
        "        data = {\n",
        "            \"Sentiment Score\": [result[\"score\"] for result in results],\n",
        "            \"Language\": [result[\"language\"] for result in results]\n",
        "        }\n",
        "        df = pd.DataFrame(data)\n",
        "        st.write(df.describe())\n",
        "\n",
        "        st.subheader(\"Interactive Visualizations\")\n",
        "        fig = px.histogram(df, x=\"Sentiment Score\", nbins=20, title=\"Sentiment Score Distribution\")\n",
        "        st.plotly_chart(fig)\n",
        "\n",
        "        lang_count = df[\"Language\"].value_counts()\n",
        "        fig2 = px.pie(lang_count, values=lang_count.values, names=lang_count.index, title=\"Language Distribution\")\n",
        "        st.plotly_chart(fig2)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ]
    }
  ]
}